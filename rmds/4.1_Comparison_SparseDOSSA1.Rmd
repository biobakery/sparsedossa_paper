---
title: "Compare with SparseDOSSA1"
author: "Siyuan Ma"
date: "11/15/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "/n/janson_lab/lab/sma/sparsedossa_paper/")
knitr::opts_chunk$set(echo=FALSE)
library(magrittr)
library(ggplot2)
```

```{r setup2}
# Registry
# batchtools::makeRegistry(file.dir = "r_batchtools_reg/Benchmarking_comparison",
#                          package = "magrittr")
batchtools::loadRegistry(file.dir = "r_batchtools_reg/Benchmarking_comparison",
                         writeable = TRUE)
batchtools::clearRegistry()

# Grid parameters
ncpus <- 1
partition <- "janson,janson_cascade,shared"
walltime <- 3600

dir_output <- "/n/janson_lab/lab/sma/sparsedossa_paper/results/Benchmarking_comparison/"
dir.create(dir_output, recursive = TRUE)
```

```{r simulation}
tb_sim <- tidyr::expand_grid(
  n = c(50, 100, 200, 400, 800),
  effect = c(0, 0.5, 1, 2, 4),
  R = seq(1, 20)
) %>%
  dplyr::mutate(i_job_sim = seq(1, dplyr::n()))
# 
# dir.create(paste0(dir_output, "Simulation/"))
# source("R/sparsedossa_utilities.R")
# for(i_job_sim in tb_sim$i_job_sim) {
#   i_tb_sim <- tb_sim[i_job_sim, ]
# 
  # fit_simulation <- trigger_sparseDOSSA_Simulator(
  #   noZeroInflate = FALSE,
  #   RandomEffect = FALSE,
  #   metadataType = "UVB",
  #   nSubjects = i_tb_sim$n,
  #   nPerSubject = 1,
  #   nMicrobes = 330,
  #   spikeMicrobes = 0.05,
  #   nMetadata = 1,
  #   spikeMetadata = 1,
  #   effectSize = i_tb_sim$effect,
  #   nIterations = 1,
  #   noParallel = TRUE,
  #   rSeed = i_job_sim
  # )
# 
# mat_count_simulated <- fit_simulation[[1]]$features
# metadata <- fit_simulation[[1]]$metadata
# save(metadata,
#      file = paste0(dir_output, "Simulation/", i_job_sim, "_metadata.RData"))
# save(mat_count_simulated,
#      file = paste0(dir_output, "Simulation/", i_job_sim, "_count.RData"))
# }
```

```{r job grid}
tb_job <- tb_sim %>% 
  tidyr::expand_grid(method = c(
    "ANCOM",
    "DESeq2",
    "edgeR",
    "limmaVOOM",
    "MaAsLin2"
  )) %>% 
  dplyr::mutate(i_job = seq(1, dplyr::n()))
save(tb_job, file = paste0(dir_output, "tb_job.RData"))
```

```{r one job}
one_job <- function(i_job) {
  source("R/DA_methods.R")
  
  i_tb_job <- tb_job[i_job, ]
  
  load(paste0(dir_output, "Simulation/", i_tb_job$i_job_sim, 
              "_metadata.RData"))
  load(paste0(dir_output, "Simulation/", i_tb_job$i_job_sim, 
              "_count.RData"))
  metadata <- as.data.frame(metadata)
  colnames(metadata) <- "datum1"
  rownames(metadata) <- 
    rownames(mat_count_simulated) <- 
    paste0("Sample", seq(1, nrow(mat_count_simulated)))
  
  mat_count_simulated <- mat_count_simulated[, apply(mat_count_simulated > 0, 2, mean) >= 0.1]
  
  if(i_tb_job$method == "ANCOM") {
    fit <- fit.ANCOM(features = mat_count_simulated,
                     metadata = metadata)
  }
   
  if(i_tb_job$method == "DESeq2") {
    fit <- fit.DESeq2(features = mat_count_simulated,
                      metadata = metadata)
  } 
  if(i_tb_job$method == "edgeR") {
    fit <- fit.edgeR(features = mat_count_simulated,
                      metadata = metadata)
  }
  if(i_tb_job$method == "limmaVOOM") {
    fit <- fit.limmaVOOM(features = mat_count_simulated,
                      metadata = metadata)
  }
  if(i_tb_job$method == "MaAsLin2") {
    dir.create(paste0(dir_output, "Maaslin2/"), showWarnings = FALSE) 
    fit <- Maaslin2::Maaslin2(input_data = t(as.matrix(mat_count_simulated)),
                              input_metadata = metadata, 
                              output = paste0(dir_output, "Maaslin2/", i_tb_job$i_job),
                              fixed_effects = "datum1",
                              normalization = "TSS", 
                              transform = "LOG")
    fit <- fit$results[, c("feature", "metadata", "coef", "pval", "qval")]
    # fit$feature <- fit$feature %>% 
    #   stringr::str_replace_all(stringr::fixed("."),
    #                            stringr::fixed("|"))
  }
  # res <- eval_res_list(fit)
  save(fit, file = paste0(dir_output, "fit_", i_tb_job$i_job, ".RData"))
  # save(res, file = paste0(dir_output, "res_", i_tb_job$i_job, ".RData"))
}
```

```{r submit jobs}
tb_ids <- batchtools::batchMap(one_job,
                               i_job = tb_job$i_job)
batchtools::batchExport(mget(ls()))
batchtools::submitJobs(ids = tb_ids$job.id,
                       resources =  list(ncpus = ncpus, 
                                         partition = partition, 
                                         walltime = walltime))
```