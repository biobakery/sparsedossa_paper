---
title: "Benchmarking different methods"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "/n/janson_lab/lab/sma/sparsedossa_paper/")
knitr::opts_chunk$set(echo=FALSE)
library(magrittr)
library(ggplot2)
```

```{r setup2}
# Registry
# batchtools::makeRegistry(file.dir = "r_batchtools_reg/all_comparison",
#                          package = "magrittr")
batchtools::loadRegistry(file.dir = "r_batchtools_reg/all_comparison", 
                         writeable = TRUE)
batchtools::clearRegistry()
rm(list = ls())

# Grid parameters
ncpus <- 1
partition <- "janson,janson_cascade,shared"
walltime <- 3600

dir_output <- "/n/janson_lab/lab/sma/sparsedossa_paper/results/all_comparison/"
dir.create(dir_output, recursive = TRUE)
```

```{r simulation}
tb_sim <- tidyr::expand_grid(
  n = c(200),
  R = seq(1, 500),
  effect = c(0, 0.5, 1, 2),
  sim_method = c("SparseDOSSA2")
) %>%
  dplyr::mutate(i_job_sim = seq(1, dplyr::n()))  
save(tb_sim, file = paste0(dir_output, "tb_sim.RData"))
# load("data/physeqs/stool.RData")
# mat_count_data <- smar::otu_table2(physeq_stool_bl)
# features_all <- phyloseq::taxa_names(physeq_stool_bl)
# features_prev <- physeq_stool_bl %>%
#   phyloseq::otu_table() %>%
#   apply(2, function(x) x > 0) %>%
#   apply(1, mean)
# features_toSpike <- features_all[order(-features_prev)[seq(1, 16)]]
# load("../sparsedossa_update/SparseDOSSA2/R/sysdata.rda")
# source("R/sparsedossa_utilities.R")
# dir.create(paste0(dir_output, "Simulation/"))
# for(i_job_sim in tb_sim$i_job_sim) {
#   set.seed(i_job_sim)
#   i_tb_sim <- tb_sim[i_job_sim, ]
#   metadata <- matrix(rbinom(n = i_tb_sim$n, size = 1, prob = 0.5),
#                      nrow = i_tb_sim$n,
#                      ncol = 1)
# 
#   if(i_tb_sim$sim_method == "Real") {
#     mat_count_simulated <-
#       mat_count_data[, sample.int(ncol(mat_count_data),  size = i_tb_sim$n)]
#     if(i_tb_sim$effect > 0) {
#       mat_count_simulated[features_toSpike, metadata[, 1] == 1] <-
#         round(mat_count_simulated[features_toSpike, metadata[, 1] == 1] * exp(i_tb_sim$effect))
#       features <- rownames(mat_count_simulated)
#       features[features %in% features_toSpike] <- paste0(features[features %in% features_toSpike], "_TP")
#       rownames(mat_count_simulated) <- features
#     }
#   }
#   if(i_tb_sim$sim_method == "SparseDOSSA1") {
#     if(i_tb_sim$effect == 0) {
#       fit_simulation <-
#         sparseDOSSA::sparseDOSSA(number_features = 330,
#                                  number_samples = i_tb_sim$n,
#                                  percent_spiked = 0,
#                                  noZeroInflate = FALSE)
#       fit_simulation <- fit_simulation$OTU_count[[1]]
#       rownames(fit_simulation) <- fit_simulation[, 1]
#       features_select <- stringr::str_subset(fit_simulation[, 1],
#                                              stringr::fixed("Feature_spike_"))
#       mat_count_simulated <- fit_simulation[features_select, -1]
#       mat_count_simulated <- apply(mat_count_simulated, 2, as.numeric)
#       dimnames(mat_count_simulated) <-
#         list(features_select,
#              paste0("Sample", seq(1, ncol(mat_count_simulated))))
#     } else {
#       fit_simulation <- trigger_sparseDOSSA_Simulator(
#         noZeroInflate = FALSE,
#         RandomEffect = FALSE,
#         metadataType = "UVB",
#         nSubjects = i_tb_sim$n,
#         nPerSubject = 1,
#         nMicrobes = 330,
#         spikeMicrobes = 0.05,
#         nMetadata = 1,
#         spikeMetadata = 1,
#         effectSize = i_tb_sim$effect * 2,
#         nIterations = 1,
#         noParallel = TRUE,
#         rSeed = i_job_sim
#       )
#       mat_count_simulated <- t(fit_simulation[[1]]$features)
#       metadata <- fit_simulation[[1]]$metadata
#     }
#   }
#   if(i_tb_sim$sim_method == "SparseDOSSA2") {
#     if(i_tb_sim$effect == 0) {
#       fit_simulation <- SparseDOSSA2::SparseDOSSA2(
#         template = Stool,
#         n_sample = i_tb_sim$n,
#         new_features = FALSE,
#         verbose = FALSE)
#       mat_count_simulated <- fit_simulation$simulated_data
#     } else {
#       effect_sizes <- rep(c(i_tb_sim$effect,
#                             -i_tb_sim$effect),
#                           8)
#       df_spike <- data.frame(
#         metadata_datum = 1,
#         feature_spiked = features_toSpike,
#         associated_property = "abundance",
#         effect_size = effect_sizes)
#       fit_simulation <- SparseDOSSA2::SparseDOSSA2(
#         template = Stool,
#         n_sample = i_tb_sim$n,
#         new_features = FALSE,
#         spike_metadata = "abundance",
#         feature_metadata_spike_df = df_spike,
#         metadata_matrix = metadata,
#         verbose = FALSE)
#       mat_count_simulated <- fit_simulation$simulated_data
#       features <- rownames(mat_count_simulated)
#       features[features %in% features_toSpike] <- paste0(features[features %in% features_toSpike], "_TP")
#       rownames(mat_count_simulated) <- features
#     }
#   }
#   save(metadata,
#        file = paste0(dir_output, "Simulation/", i_job_sim, "_metadata.RData"))
#   save(mat_count_simulated,
#        file = paste0(dir_output, "Simulation/", i_job_sim, "_count.RData"))
# }
```

```{r job grid}
tb_job <- tb_sim %>%
  dplyr::filter(R %in% seq(1, 481, by = 20)) %>%
  tidyr::expand_grid(method = c(
    "ANCOM",
    "DESeq2",
    "edgeR",
    "limmaVOOM",
    "MaAsLin2"
  )) %>%
  dplyr::mutate(i_job = seq(1, dplyr::n()))
save(tb_job, file = paste0(dir_output, "tb_job.RData"))
```

```{r one_job}
one_job <- function(i_job) {
  source("R/DA_methods.R")
  load(paste0(dir_output, "tb_job.RData"))
  load(paste0(dir_output, "tb_sim.RData"))
  
  i_tb_job <- tb_job[i_job, ]
  i_tb_sim <- tb_sim %>% 
    dplyr::filter(n == i_tb_job$n, 
                  sim_method == i_tb_job$sim_method, 
                  effect == i_tb_job$effect,
                  R %in% (i_tb_job$R + seq(0, 19)))
  
  for(r in seq(1, 20)) {
    load(paste0(dir_output, "Simulation/", i_tb_sim$i_job_sim[r], 
                "_metadata.RData"))
    load(paste0(dir_output, "Simulation/", i_tb_sim$i_job_sim[r], 
                "_count.RData"))
    metadata <- as.data.frame(metadata)
    colnames(metadata) <- "datum1"
    rownames(metadata) <- 
      colnames(mat_count_simulated) <- 
      paste0("Sample", seq(1, ncol(mat_count_simulated)))
    
  # filter features that are too absent
  mat_count_simulated <- mat_count_simulated[apply(mat_count_simulated > 0, 1, mean) >= 0.1, ]
  
  if(i_tb_job$method == "ANCOM") {
    fit <- fit.ANCOM(features = t(mat_count_simulated),
                     metadata = metadata)
  }
   
  if(i_tb_job$method == "DESeq2") {
    fit <- fit.DESeq2(features = t(mat_count_simulated),
                      metadata = metadata)
  } 
  if(i_tb_job$method == "edgeR") {
    fit <- fit.edgeR(features = t(mat_count_simulated),
                      metadata = metadata)
  }
  if(i_tb_job$method == "limmaVOOM") {
    fit <- fit.limmaVOOM(features = t(mat_count_simulated),
                      metadata = metadata)
  }
  if(i_tb_job$method == "MaAsLin2") {
    dir.create(paste0(dir_output, "Maaslin2/"), showWarnings = FALSE) 
    fit <- Maaslin2::Maaslin2(input_data = mat_count_simulated,
                              input_metadata = metadata, 
                              output = paste0(dir_output, "Maaslin2/", i_tb_job$i_job),
                              fixed_effects = "datum1",
                              normalization = "TSS", 
                              transform = "LOG")
    fit <- fit$results[, c("feature", "metadata", "coef", "pval", "qval")]
    fit$feature <- fit$feature %>% 
      stringr::str_replace_all(stringr::fixed("."),
                               stringr::fixed("|"))
  }
  # res <- eval_res_list(fit)
  save(fit, file = paste0(dir_output, "fit_", i_tb_job$i_job, "_", r, ".RData"))
  # save(res, file = paste0(dir_output, "res_", i_tb_job$i_job, ".RData"))
  }
}
```

```{r submit jobs}
tb_ids <- batchtools::batchMap(one_job,
                               i_job = seq(1, nrow(tb_job)))
batchtools::batchExport(mget(ls()))
batchtools::submitJobs(ids = tb_ids$job.id[seq(1, 20)],
                       resources =  list(ncpus = ncpus,
                                         partition = partition,
                                         walltime = walltime))
# batchtools::submitJobs(ids = batchtools::findNotSubmitted()$job.id,
#                        resources =  list(ncpus = ncpus,
#                                          partition = partition,
#                                          walltime = walltime))
```