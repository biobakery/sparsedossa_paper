---
title: "Benchmarking different methods"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "/n/janson_lab/lab/sma/sparsedossa_paper/")
knitr::opts_chunk$set(echo=FALSE)
library(magrittr)
library(ggplot2)
```

```{r setup2}
# Registry
# batchtools::makeRegistry(file.dir = "r_batchtools_reg/all_comparison",
#                          package = "magrittr")
batchtools::loadRegistry(file.dir = "r_batchtools_reg/all_comparison", 
                         writeable = TRUE)
batchtools::clearRegistry()
rm(list = ls())

# Grid parameters
ncpus <- 1
partition <- "shared"
walltime <- 3600

dir_output <- "results/all_comparison/"
dir.create(dir_output, recursive = TRUE)
```

```{r simulation}
tb_sim <- tidyr::expand_grid(
  n = c(200),
  R = seq(1, 500),
  effect = c(0, 0.5, 1, 2),
  sim_method = c("SparseDOSSA2")
) %>%
  dplyr::mutate(i_job_sim = seq(1, dplyr::n()))  
save(tb_sim, file = paste0(dir_output, "tb_sim.RData"))
load("data/physeqs/stool.RData")
mat_count_data <- smar::otu_table2(physeq_stool_bl)
features_all <- phyloseq::taxa_names(physeq_stool_bl)
features_prev <- physeq_stool_bl %>%
  phyloseq::otu_table() %>%
  apply(2, function(x) x > 0) %>%
  apply(1, mean)
features_toSpike <- features_all[order(-features_prev)[seq(1, 16)]]
load("../sparsedossa_update/SparseDOSSA2/R/sysdata.rda")
dir.create(paste0(dir_output, "Simulation/"))
for(i_job_sim in tb_sim$i_job_sim) {
  set.seed(i_job_sim)
  i_tb_sim <- tb_sim[i_job_sim, ]
  metadata <- matrix(rbinom(n = i_tb_sim$n, size = 1, prob = 0.5),
                     nrow = i_tb_sim$n,
                     ncol = 1)
  
  if(i_tb_sim$effect == 0) {
    fit_simulation <- SparseDOSSA2::SparseDOSSA2(
      template = Stool,
      n_sample = i_tb_sim$n,
      new_features = FALSE,
      verbose = FALSE)
    mat_count_simulated <- fit_simulation$simulated_data
  } else {
    effect_sizes <- rep(c(i_tb_sim$effect,
                          -i_tb_sim$effect),
                        8)
    df_spike <- data.frame(
      metadata_datum = 1,
      feature_spiked = features_toSpike,
      associated_property = "abundance",
      effect_size = effect_sizes)
    fit_simulation <- SparseDOSSA2::SparseDOSSA2(
      template = Stool,
      n_sample = i_tb_sim$n,
      new_features = FALSE,
      spike_metadata = "abundance",
      feature_metadata_spike_df = df_spike,
      metadata_matrix = metadata,
      verbose = FALSE)
    mat_count_simulated <- fit_simulation$simulated_data
    features <- rownames(mat_count_simulated)
    features[features %in% features_toSpike] <- paste0(features[features %in% features_toSpike], "_TP")
    rownames(mat_count_simulated) <- features
  }
  save(metadata,
       file = paste0(dir_output, "Simulation/", i_job_sim, "_metadata.RData"))
  save(mat_count_simulated,
       file = paste0(dir_output, "Simulation/", i_job_sim, "_count.RData"))
}
```

```{r job grid}
tb_job <- tb_sim %>%
  tidyr::expand_grid(method = c(
    "ANCOM",
    "limmaVOOM",
    "MaAsLin2"
  )) %>%
  dplyr::mutate(i_job = seq(1, dplyr::n()))
save(tb_job, file = paste0(dir_output, "tb_job.RData"))
```

```{r one_job}
one_job <- function(i_job) {
  source("R/DA_methods.R")
  load(paste0(dir_output, "tb_job.RData"))
  load(paste0(dir_output, "tb_sim.RData"))
  
  i_tb_job <- tb_job[i_job, ]
  i_tb_sim <- tb_sim %>% 
    dplyr::filter(n == i_tb_job$n, 
                  sim_method == i_tb_job$sim_method, 
                  effect == i_tb_job$effect,
                  R %in% (i_tb_job$R + seq(0, 19)))
  
  for(r in seq(1, 20)) {
    load(paste0(dir_output, "Simulation/", i_tb_sim$i_job_sim[r], 
                "_metadata.RData"))
    load(paste0(dir_output, "Simulation/", i_tb_sim$i_job_sim[r], 
                "_count.RData"))
    metadata <- as.data.frame(metadata)
    colnames(metadata) <- "datum1"
    rownames(metadata) <- 
      colnames(mat_count_simulated) <- 
      paste0("Sample", seq(1, ncol(mat_count_simulated)))
    
    # filter features that are too absent
    mat_count_simulated <- mat_count_simulated[apply(mat_count_simulated > 0, 1, mean) >= 0.1, ]
    
    if(i_tb_job$method == "ANCOM") {
      fit <- fit.ANCOM(features = t(mat_count_simulated),
                       metadata = metadata)
    }
    
    if(i_tb_job$method == "limmaVOOM") {
      fit <- fit.limmaVOOM(features = t(mat_count_simulated),
                           metadata = metadata)
    }
    if(i_tb_job$method == "MaAsLin2") {
      dir.create(paste0(dir_output, "Maaslin2/"), showWarnings = FALSE) 
      fit <- Maaslin2::Maaslin2(input_data = mat_count_simulated,
                                input_metadata = metadata, 
                                output = paste0(dir_output, "Maaslin2/", i_tb_job$i_job),
                                fixed_effects = "datum1",
                                normalization = "TSS", 
                                transform = "LOG")
      fit <- fit$results[, c("feature", "metadata", "coef", "pval", "qval")]
      fit$feature <- fit$feature %>% 
        stringr::str_replace_all(stringr::fixed("."),
                                 stringr::fixed("|"))
    }
    save(fit, file = paste0(dir_output, "fit_", i_tb_job$i_job, "_", r, ".RData"))
  }
}
```

```{r submit jobs}
tb_ids <- batchtools::batchMap(one_job,
                               i_job = seq(1, nrow(tb_job)))
batchtools::batchExport(mget(ls()))
batchtools::submitJobs(ids = batchtools::findNotSubmitted()$job.id,
                       resources =  list(ncpus = ncpus,
                                         partition = partition,
                                         walltime = walltime))
```